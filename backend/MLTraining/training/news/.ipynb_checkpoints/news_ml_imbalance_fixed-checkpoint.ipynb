{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471cf63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score\n",
    "from hdfs import InsecureClient\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "hdfs_client = InsecureClient('http://localhost:9870', user='bigdata')  \n",
    "\n",
    "# Read the CSV file from HDFS\n",
    "with hdfs_client.read('/news/news-data.csv', encoding='latin-1') as reader:\n",
    "    data = pd.read_csv(reader, names=['sentiment', 'text'])\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.update(punctuation)\n",
    "\n",
    "# this function return the part of speech of a word.\n",
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "# Function to clean our text.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def clean_review(text):\n",
    "    clean_text = []\n",
    "    for w in word_tokenize(text):\n",
    "        if w.lower() not in stop:\n",
    "            pos = pos_tag([w])\n",
    "            new_w = lemmatizer.lemmatize(w, pos=get_simple_pos(pos[0][1]))\n",
    "            clean_text.append(new_w)\n",
    "    return clean_text\n",
    "\n",
    "def join_text(text):\n",
    "    return \" \".join(text)\n",
    "\n",
    "data.text = data.text.apply(clean_review)\n",
    "data.text = data.text.apply(join_text)\n",
    "\n",
    "train, test = train_test_split(data,test_size = 0.1 , random_state = 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f52d7852",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "x_train_resampled, y_train_resampled = ros.fit_resample(train[['text']], train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aba670d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expand plant schedule operational middle Octob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-service automation big role Fujitsu 's gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>addition exist service counter area reception ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delivery start immediately June 2008 complete ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kesko Agro Lietuva agricultural machinery grai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7768</th>\n",
       "      <td>acquisition Solteq expand solution offering Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7769</th>\n",
       "      <td>Finnish Suominen Corporation specialises wet w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7770</th>\n",
       "      <td>Significance Teleste emphasise large size grow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>Operating profit nine-month period increase EU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7772</th>\n",
       "      <td>`` Government professional approach assess offer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7773 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     expand plant schedule operational middle Octob...\n",
       "1     Self-service automation big role Fujitsu 's gl...\n",
       "2     addition exist service counter area reception ...\n",
       "3     Delivery start immediately June 2008 complete ...\n",
       "4     Kesko Agro Lietuva agricultural machinery grai...\n",
       "...                                                 ...\n",
       "7768  acquisition Solteq expand solution offering Mi...\n",
       "7769  Finnish Suominen Corporation specialises wet w...\n",
       "7770  Significance Teleste emphasise large size grow...\n",
       "7771  Operating profit nine-month period increase EU...\n",
       "7772   `` Government professional approach assess offer\n",
       "\n",
       "[7773 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d6f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "count_vec = CountVectorizer(max_features=4000, ngram_range=(1, 2), max_df=1, min_df=0)\n",
    "x_train_features = count_vec.fit_transform(x_train_resampled['text'])\n",
    "x_test_features = count_vec.transform(test['text'])\n",
    "x_train_features = x_train_features.todense()\n",
    "x_test_features = x_test_features.todense()\n",
    "\n",
    "x_data = np.concatenate((x_train_resampled['text'].values, test['text'].values))\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(x_data)\n",
    "with open('/home/bigdata/project-folder/ver_0.3/backend/MLTraining/training/news/tokenizer_news.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "y_train_resampled = y_train_resampled.map({'positive': 2, 'neutral': 1, 'negative': 0})\n",
    "y_test = test[\"sentiment\"]\n",
    "y_test = y_test.map({'positive': 2, 'neutral': 1, 'negative': 0})\n",
    "\n",
    "print(x_train_features.shape[1])\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y_train_resampled = to_categorical(y_train_resampled)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "def fit_model(optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Definisikan arsitektur model\n",
    "    model.add(Dense(units=512, activation='relu', input_dim=x_train_features.shape[1]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=3, activation='softmax'))\n",
    "    \n",
    "    # Kompilasi model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # Latih model\n",
    "    history = model.fit(x_train_features, y_train_resampled, validation_data=(x_test_features, y_test), epochs=100, verbose=1)\n",
    "       \n",
    "    # Simpan model\n",
    "    save_dir = './ver_0.3/backend/MLTraining/training/news'\n",
    "    model_name = 'model_' + optimizer + '.h5'\n",
    "\n",
    "    model_save_path = os.path.join(save_dir, model_name)\n",
    "    model.save(model_save_path)\n",
    "    print(\"Model saved at\", model_save_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Contoh pemanggilan fungsi\n",
    "optimizers = ['adam']\n",
    "for i, opt in enumerate(optimizers):\n",
    "    model = fit_model(opt)\n",
    "\n",
    "\n",
    "# Prediksi pada data validasi\n",
    "predictions = model.predict(x_test_features)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "print(f1_macro)\n",
    "print(classification_report(y_true, y_pred, target_names=['negative', 'neutral', 'positive']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf78ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "63cc5460",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738efe22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
